{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b47ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation function with detailed metrics\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "# import logging\n",
    "\n",
    "\n",
    "# class LabelSmoothingLoss(nn.Module):\n",
    "#     def __init__(self, classes=46, smoothing=0.05):\n",
    "#         super(LabelSmoothingLoss, self).__init__()\n",
    "#         self.confidence = 1.0 - smoothing\n",
    "#         self.smoothing = smoothing\n",
    "#         self.cls = classes\n",
    "\n",
    "#     def forward(self, x, target):\n",
    "#         logprobs = F.log_softmax(x, dim=-1)\n",
    "#         nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "#         nll_loss = nll_loss.squeeze(1)\n",
    "#         smooth_loss = -logprobs.mean(dim=-1)\n",
    "#         loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "#         return loss.mean()\n",
    "    \n",
    "# criterion = nn.CrossEntropyLoss(\n",
    "#     label_smoothing=config.get('label_smoothing', 0.05)\n",
    "# )\n",
    "\n",
    "# def evaluate_model(model, test_loader, device, criterion, num_classes=46):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in test_loader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * images.size(0)\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "#             all_preds.extend(predicted.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     test_acc = correct / total\n",
    "\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "#         all_labels, all_preds, average=None, labels=range(num_classes), zero_division=0\n",
    "#     )\n",
    "#     conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "\n",
    "#     logger.info(f\"Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "#     return test_loss, test_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- Imports ----------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# ---------------- Model Definition ----------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, dropout_rate=0.05):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ) if stride != 1 or in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout(out)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class HFCLayer(nn.Module):\n",
    "    def __init__(self, num_classes, D_b):\n",
    "        super().__init__()\n",
    "        self.V = nn.Parameter(torch.randn(num_classes, D_b))\n",
    "        self.bn = nn.BatchNorm1d(num_classes * D_b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        U_b = x.sum(dim=1)\n",
    "        T_b = U_b.unsqueeze(1) * self.V.unsqueeze(0)\n",
    "        batch_size = T_b.size(0)\n",
    "        T_b_flat = T_b.view(batch_size, -1)\n",
    "        T_b_bn = self.bn(T_b_flat)\n",
    "        T_b_bn = T_b_bn.view(batch_size, self.V.size(0), -1)\n",
    "        return torch.relu(T_b_bn).sum(dim=2)\n",
    "\n",
    "class MergingLayer(nn.Module):\n",
    "    def __init__(self, num_branches=3):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.ones(num_branches) / num_branches)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        weights = torch.softmax(self.w, dim=0)\n",
    "        return sum(w * logit for w, logit in zip(weights, inputs))\n",
    "\n",
    "class BMCNNBase(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.05):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            ResidualBlock(1, 128, 1, dropout_rate),\n",
    "            ResidualBlock(128, 128, 1, dropout_rate),\n",
    "            ResidualBlock(128, 128, 1, dropout_rate),\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, 1, dropout_rate),\n",
    "            ResidualBlock(256, 256, 1, dropout_rate),\n",
    "            ResidualBlock(256, 256, 1, dropout_rate),\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            ResidualBlock(256, 512, 1, dropout_rate),\n",
    "            ResidualBlock(512, 512, 1, dropout_rate),\n",
    "            ResidualBlock(512, 512, 1, dropout_rate),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_block1(x)\n",
    "        x2 = self.conv_block2(self.pool1(x1))\n",
    "        x3 = self.conv_block3(self.pool2(x2))\n",
    "        return x1, x2, x3\n",
    "\n",
    "class EnhancedBMCNNwHFCs(BMCNNBase):\n",
    "    def __init__(self, num_classes=46, dropout_rate=0.05):\n",
    "        super().__init__(dropout_rate)\n",
    "        self.hfc1 = HFCLayer(num_classes, 32*32)\n",
    "        self.hfc2 = HFCLayer(num_classes, 16*16)\n",
    "        self.hfc3 = HFCLayer(num_classes, 8*8)\n",
    "        self.merging = MergingLayer(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3 = super().forward(x)\n",
    "        logit1 = self.hfc1(x1.view(x1.size(0), x1.size(1), -1))\n",
    "        logit2 = self.hfc2(x2.view(x2.size(0), x2.size(1), -1))\n",
    "        logit3 = self.hfc3(x3.view(x3.size(0), x3.size(1), -1))\n",
    "        return self.merging((logit1, logit2, logit3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Test Loss: 5.9583 - Test Acc: 0.0212\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Custom transform for data augmentation\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "test_dir = \"Test\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(test_dir, transform=train_transform)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_loader_ = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "# 1. Setup Criterion with Label Smoothing\n",
    "# Using the built-in implementation available in torch.nn\n",
    "def get_criterion(config):\n",
    "    smoothing = config.get('label_smoothing', 0.05)\n",
    "    return nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "\n",
    "# 2. Evaluation Function (With Labels)\n",
    "def evaluate_model(model, test_loader, device, criterion, num_classes=46):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Get class indices\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    # Concatenate all results efficiently\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = (all_preds == all_labels).mean()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=None, labels=range(num_classes), zero_division=0\n",
    "    )\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "\n",
    "    logger.info(f\"Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "    return test_loss, test_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "# 3. Pure Inference Function (Without Labels / For Production)\n",
    "def run_inference(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Use this for deployment where you only have images.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            # Handle cases where data_loader might return (img, label) \n",
    "            if isinstance(images, (list, tuple)):\n",
    "                images = images[0]\n",
    "                \n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            \n",
    "            # Apply softmax to get calibrated probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            predictions.append(predicted.cpu())\n",
    "            probabilities.append(probs.cpu())\n",
    "\n",
    "    return torch.cat(predictions).numpy(), torch.cat(probabilities).numpy()\n",
    "\n",
    "# Example Usage Implementation\n",
    "if __name__ == \"__main__\":\n",
    "    # Mock Config\n",
    "    config = {'label_smoothing': 0.05}\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize loss\n",
    "    criterion = get_criterion(config)\n",
    "    MODEL_PATH = \"models/best_model.pth\"\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    Basnet = EnhancedBMCNNwHFCs(num_classes=46, dropout_rate=0.0).to(device)\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    Basnet.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    Basnet.eval()\n",
    "    print(\"Model loaded successfully on device:\", device)\n",
    "    model = Basnet.to(device)\n",
    "    test_loader = test_loader_\n",
    "    \n",
    "    # To evaluate accuracy and F1:\n",
    "    results = evaluate_model(model, test_loader, device, criterion)\n",
    "    \n",
    "    # To just get predictions:\n",
    "    preds, probs = run_inference(model, test_loader, device)\n",
    "\n",
    "#print final loss and accuracy\n",
    "    print(f\"Final Test Loss: {results[0]:.4f}, Final Test Accuracy: {results[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
